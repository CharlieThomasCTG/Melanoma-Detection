{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDriIbfa5lwD"
   },
   "source": [
    "**Problem statement**: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvdV0dn-0tKJ"
   },
   "source": [
    "**Data Summary:**\n",
    "\n",
    "The dataset consists of 2357 images of malignant and benign oncological diseases, which were formed from the International Skin Imaging Collaboration (ISIC). All images were sorted according to the classification taken with ISIC, and all subsets were divided into the same number of images, with the exception of melanomas and moles, whose images are slightly dominant.\n",
    "\n",
    "The data set contains the following diseases:\n",
    "1. Actinic keratosis\n",
    "2. Basal cell carcinoma\n",
    "3. Dermatofibroma\n",
    "4. Melanoma\n",
    "5. Nevus\n",
    "6. Pigmented benign keratosis\n",
    "7. Seborrheic keratosis\n",
    "8. Squamous cell carcinoma\n",
    "9. Vascular lesion\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfcpIXQZN2Rh"
   },
   "source": [
    "### Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WC8xCQuELWms"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading And Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path for train and test images\n",
    "## Todo: Update the paths of the train and test dataset\n",
    "data_dir_train = pathlib.Path(\"Train\")\n",
    "data_dir_test = pathlib.Path('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpUsRQwOOL72"
   },
   "source": [
    "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqksN1w5Fu-N",
    "outputId": "117a20d4-9147-4371-aeb7-c91923077ce1"
   },
   "outputs": [],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "print(image_count_train)\n",
    "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
    "print(image_count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created train & validation dataset from the train directory with a batch size of 32 .Resized images to 180*180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLfcXcZ9LjGv"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5f5y43GPog1"
   },
   "source": [
    "Use 80% of the images for training, and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1BWmDzr7w-5",
    "outputId": "9508a525-0f12-4ce4-df7c-3f221a3a006f"
   },
   "outputs": [],
   "source": [
    "## Creating Training Dataset\n",
    "## Used seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
    "## Resized images to the size img_height*img_width, while writting the dataset\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYch6-SR-i2g",
    "outputId": "d594b906-496d-4835-8760-3975eb302476"
   },
   "outputs": [],
   "source": [
    "## Creating Validation Dataset\n",
    "## Used seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
    "## Resized images to the size img_height*img_width, while writting the dataset\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1V0Okk-40v3",
    "outputId": "a5a4ab22-abe1-4fa6-9890-c0d6bbad9af8"
   },
   "outputs": [],
   "source": [
    "## Creating Test Dataset\n",
    "## Used seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
    "## Resized images to the size img_height*img_width, while writting the dataset\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_test,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bk0RV7G7-nad",
    "outputId": "2c20377f-b58c-4eca-b7b6-f2e050675bd6"
   },
   "outputs": [],
   "source": [
    "# List out all the classes of skin cancer and store them in a list. \n",
    "# You can find the class names in the class_names attribute on these datasets. \n",
    "# These correspond to the directory names in alphabetical order.\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbsm5oYiQH_b"
   },
   "source": [
    "# Dataset Visualisation\n",
    "###  Created a code to visualize one instance of all the nine classes present in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "tKILZ48I-q1k",
    "outputId": "72b85239-b576-413d-e020-3c75f54ba663"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch,labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cAZPYaeQjQy"
   },
   "source": [
    "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzVXBHiyQ7_I"
   },
   "source": [
    "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
    "\n",
    "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wZlKRBEGNtU"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JEAF6-sRyz8"
   },
   "source": [
    "# Model Building & training\n",
    "### Created a CNN model, which can accurately detect 9 classes present in the dataset.\n",
    "### Defined appropriate optimiser and loss function for model training.\n",
    "### Trained the model for ~20 epochs.\n",
    "### Explained the findings after the model fit with evidence if the model overfits or underfits.\n",
    "####  Use ```layers.experimental.preprocessing.Rescaling``` to normalize pixel values between (0,1). The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network. Here, it is good to standardize values to be in the `[0, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "normalization = layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9\n",
    "model = Sequential([layers.experimental.preprocessing.Rescaling(1./255,input_shape=(img_height,img_width,3)),\n",
    "                    layers.Conv2D(16,kernel_size=(3,3),padding='same',strides=(1,1),activation='relu'),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Conv2D(32,kernel_size=(3,3),padding='same',strides=(1,1),activation='relu'),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Conv2D(64,kernel_size=(3,3),padding='same',strides=(1,1),activation='relu'),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(128,activation='softmax'),\n",
    "                    layers.Dense(num_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ync9xoW7GZgn",
    "outputId": "64160d44-e0f9-4465-9609-96600bcaf114"
   },
   "outputs": [],
   "source": [
    "### Builing a Model\n",
    "num_classes=9\n",
    "\n",
    "model = Sequential()\n",
    "#Adding a  preprocessing_layers to rescale the inputs\n",
    "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height,img_width,3)))\n",
    "model.add(Conv2D(16,kernel_size=(3,3),padding='same',strides=(1,1),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(1,1),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),padding='same',strides=(1,1),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='softmax'))\n",
    "model.add(Dense(num_classes))\n",
    "\n",
    "\n",
    "## Number of classes is 9\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDKzJmHwSCtt"
   },
   "source": [
    "### Compile the model\n",
    "Choose an appropirate optimiser and loss function for model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XB8wKtiPGe1j"
   },
   "outputs": [],
   "source": [
    "# Selected an appropirate optimiser 'adam' and loss function 'SparseCategoricalCrossentropy'\n",
    "\n",
    "optimizer = 'adam'\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljD_83rwSl5O"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kkfw2rJXGlYC",
    "outputId": "4fb5f91e-5627-4d00-8d8a-6811754e3d61"
   },
   "outputs": [],
   "source": [
    "#Train the model with 20 epochs and batch size =32.\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,steps_per_epoch=2,\n",
    "  batch_size=batch_size,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3679V8OShSE"
   },
   "source": [
    "### Visualizing training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "R1xkgk5nGubz",
    "outputId": "3b5b1eef-b66a-46a6-c417-4d42d96bd3e8"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvPphJYuSZhK"
   },
   "source": [
    "#### Model Overfit or Underfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the model accuracy and loss on train and validation dataset\n",
    "loss, accuracy = model.evaluate(train_ds, verbose=1,)\n",
    "loss_v, accuracy_v = model.evaluate(val_ds, verbose=1)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Validation Accuracy: \",accuracy_v)\n",
    "print(\"Loss: \",loss)\n",
    "print(\"Validation Loss\", loss_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQO0_mZCLSWr",
    "outputId": "dde217c9-10d6-4ef8-b543-ba25c6245295"
   },
   "source": [
    "### findings\n",
    "#### There is difference of more than 10 percent between training and validation accuracy. Model is Overfitting and we need to chose right data augumentation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with dropout(),BatchNormalization() preprocessed with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22hljAl6GykA",
    "outputId": "00a82d39-8d5a-4acb-caee-9235e42549a9"
   },
   "outputs": [],
   "source": [
    "#Data Augmentaion using ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "image_class = ['nevus','melanoma','basal_cell_caricoma','actinic_keratosis','vasc_lesion','dermatofibroma', 'pigmented_keratosis', 'seborrheic_keratosis', 'squamous_carci']\n",
    "\n",
    "train_batches = datagen.flow_from_directory(data_dir_train, \n",
    "    target_size = (180,180),\n",
    "    classes = image_class,\n",
    "    batch_size = 64\n",
    " )\n",
    "\n",
    "valid_batches = datagen.flow_from_directory(data_dir_test, \n",
    "    target_size = (180,180),\n",
    "    classes = image_class,\n",
    "    batch_size = 64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "XEjPWh8GG0C7",
    "outputId": "5e9794f9-292b-46e6-feda-23a82cb5a0fa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize how your augmentation strategy works for one instance of training image.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_1 = Sequential()\n",
    "#Adding a  preprocessing_layers to rescale the inputs\n",
    "model_1.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height,img_width,3)))\n",
    "model_1.add(Conv2D(16,kernel_size=(3,3),padding='same',strides=(1,1),activation='relu'))\n",
    "model_1.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# Adding Dropout Layer\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "model_1.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(1,1),activation='relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.4))\n",
    "\n",
    "model_1.add(Conv2D(64,kernel_size=(3,3),padding='same',strides=(2,2),activation='relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.4))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "\n",
    "model_1.add(Dense(128, activation='softmax'))\n",
    "model_1.add(Dense(num_classes))\n",
    "\n",
    "\n",
    "## Number of classes is 9\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfUWFp96UIAN"
   },
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-7yTm8IG8zR"
   },
   "outputs": [],
   "source": [
    "## Selected an appropirate optimiser 'adam' and loss function 'categorical_crossentropy'\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxROM6O_cHnp"
   },
   "source": [
    "I have used an annealing method of the learning rate (LR) in order to make the optimizer converge faster and closest to the global minimum of the loss function, \n",
    "\n",
    "The LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence. However the sampling is very poor with an high LR and the optimizer could probably fall into a local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3jffRAAcBwS"
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    factor=0.5, \n",
    "    min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC-D_RWOURp6"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcPfkUASHBf9",
    "outputId": "b48f6f4f-8465-4881-d456-1643232bbcc8"
   },
   "outputs": [],
   "source": [
    "#train your model for 20 epochs\n",
    "epochs = 20\n",
    "batch_size = 10\n",
    "history = model_1.fit(train_batches,\n",
    "                     epochs = epochs,\n",
    "                      steps_per_epoch=5,\n",
    "                      verbose = 1, \n",
    "                      validation_data=valid_batches, \n",
    "                      callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhNOKtSyUYzC"
   },
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjN_F4QxHIsh"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "print(history.history.keys, \":\")\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the model accuracy and loss on train and validation dataset\n",
    "loss, accuracy = model_1.evaluate(train_batches, verbose=1,)\n",
    "loss_v, accuracy_v = model_1.evaluate(valid_batches, verbose=1)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Validation Accuracy: \",accuracy_v)\n",
    "print(\"Loss: \",loss)\n",
    "print(\"Validation Loss\", loss_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "#### Model is overfitting as there is substantial difference between Training and validation dataset accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "hya16hY996kW",
    "outputId": "e748c391-ace1-4b10-954e-87b5641f0668"
   },
   "outputs": [],
   "source": [
    "#Plotting the length of the 9 classess of skin disease\n",
    "import matplotlib.pyplot as plt\n",
    "data = dict()\n",
    "\n",
    "for i in class_names:\n",
    "  data[i] = []\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "for images, labels in train_ds:\n",
    "  for i in range(9):\n",
    "    data[class_names[labels[i]]].append(images[i].numpy().astype(\"uint8\"))\n",
    "\n",
    "for i in data:\n",
    "  data[i] = len(data[i]) \n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(20)\n",
    "\n",
    "plt.bar(range(len(data)), list(data.values()), align='center')\n",
    "plt.xticks(range(len(data)), list(data.keys()))\n",
    "plt.xticks(rotation = 25)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4csQL1dvO0b2"
   },
   "source": [
    "\n",
    "#### - Which class has the least number of samples? \n",
    "**seborrheic keratosis**\n",
    "#### - Which classes dominate the data in terms proportionate number of samples?\n",
    "**pigmented benign keratosis** dominates the data of count more than 100 in training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing the Overfit \n",
    "\n",
    "### Selected Python package 'Augmentor' an appropriate data augmentation strategy to resolve underfitting/overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Egt9EHjR-Dd",
    "outputId": "bff9e613-daca-4900-9de3-fd9fd6c338bf"
   },
   "outputs": [],
   "source": [
    "# importing the libraray Augmentor\n",
    "import Augmentor\n",
    "for i in class_names:\n",
    "    csp = str(data_dir_train)\n",
    "    fullpath = csp + \"/\" + i\n",
    "    p = Augmentor.Pipeline(fullpath)\n",
    "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcBIFZGbWuFa"
   },
   "source": [
    "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxWcMqZhdRWz",
    "outputId": "560f01fe-8d06-4aa2-e216-7ca1084ab667"
   },
   "outputs": [],
   "source": [
    "#Printing the total count of image\n",
    "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
    "print(image_count_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ5KarKq4kWJ"
   },
   "source": [
    "### Lets see the distribution of augmented data after adding new images to the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tODrYIY2nxJ",
    "outputId": "8ea1fb28-d648-480c-daa8-49156d0849e5"
   },
   "outputs": [],
   "source": [
    "#Creating a new folder 'Output' \n",
    "path_list = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZvVdF7g3E1z",
    "outputId": "c25e2d1d-e204-4c4b-88e0-89bddf1ec90a"
   },
   "outputs": [],
   "source": [
    "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
    "lesion_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okcqVFAA2nxK"
   },
   "outputs": [],
   "source": [
    "\n",
    "dataframe_dict_new = dict(zip(path_list, lesion_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njzBxTNT2nxK"
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
    "new_df = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5j45rmxd2nxK",
    "outputId": "82830233-d1ff-409d-eac9-34457a9fe485"
   },
   "outputs": [],
   "source": [
    "new_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NirFBvGPmgI"
   },
   "source": [
    "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0haOU11Ey8ey"
   },
   "source": [
    "#### Create a training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4ZY11judRWz",
    "outputId": "be282d7a-7745-4990-ba30-50c3c654691d"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "#data_dir_train=\"/content/gdrive/MyDrive/CNN/Skin_Data_Store/Train\"\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'training',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwNJVDuBP5kf"
   },
   "source": [
    "#### Create a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TX191d_3dRW0",
    "outputId": "cf23df8f-c136-4681-c83c-8fbccd419b84"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'validation',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaoWeOEpVjqH"
   },
   "source": [
    "# Model Building after data augmentation using library Augmentor\n",
    "#### Create your model (make sure to include normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ch0MuKvFVr7O",
    "outputId": "a8fbc666-8f44-4bfd-b05c-f2920af79370"
   },
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "#Adding a  preprocessing_layers to rescale the inputs\n",
    "model_2.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height,img_width,3)))\n",
    "model_2.add(Conv2D(16,kernel_size=(3,3),padding='same',strides=(2,2),activation='relu'))\n",
    "model_2.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# Adding Dropout Layer\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2),activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.4))\n",
    "\n",
    "model_2.add(Conv2D(64,kernel_size=(3,3),padding='same',strides=(2,2),activation='relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.4))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "\n",
    "model_2.add(Dense(128, activation='softmax'))\n",
    "model_2.add(Dense(num_classes))\n",
    "\n",
    "\n",
    "## Number of classes is 9\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bu5N9LxkVx1B"
   },
   "source": [
    "#### Compile your model (Choose optimizer and loss function appropriately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H47GWmLbdRW1"
   },
   "outputs": [],
   "source": [
    "## Selected an appropirate optimiser 'adam' and loss function 'SparseCategoricalCrossentropy'\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "optimizer = 'adam'\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model_2.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gS-Y1bJV7uy"
   },
   "source": [
    "####  Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcV6OdI4dRW1",
    "outputId": "43204cd4-cbd8-496f-d362-6c7fa3f75f96"
   },
   "outputs": [],
   "source": [
    "#Training model on 30 epochs with learning_rate_reductions\n",
    "epochs = 30\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    factor=0.5, \n",
    "    min_lr=0.00001)\n",
    "\n",
    "batch_size = 10\n",
    "history = model_2.fit(train_ds,\n",
    "                      epochs = epochs,\n",
    "                      steps_per_epoch =5, \n",
    "                      verbose = 1, \n",
    "                      validation_data=val_ds, \n",
    "                      callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuvfCTsBWLMp"
   },
   "source": [
    "####  Visualize the model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "lCTXwfkTdRW1",
    "outputId": "8747ae63-ff2c-48ee-f34a-a129f5425cf8"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the model accuracy and loss on train and validation dataset\n",
    "loss, accuracy = model_2.evaluate(train_ds, verbose=1,)\n",
    "loss_v, accuracy_v = model_2.evaluate(val_ds, verbose=1)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Validation Accuracy: \",accuracy_v)\n",
    "print(\"Loss: \",loss)\n",
    "print(\"Validation Loss\", loss_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "#### Managing the class imbalance has helped in reducing overfit of the data.Loss is reduced but,  the Acurracy has gone down substantially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "source": [
    "#### Did you get rid of underfitting/overfitting? Did class rebalance help?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHKAWRZyfYlD"
   },
   "source": [
    "Managing the class imbalance has helped in reducing overfit of the data.Loss is reduced\n",
    "But  the Acurracy has gone down substantially\n",
    "\n",
    "\n",
    "Initially we tried without the ImageDataGenerator which lead data to over fit\n",
    "\n",
    "Then we introduced dropout,batch normalisation and ImageDataGenerator which increased  the over fit\n",
    "\n",
    "Finallly, we tried manage  the data imbalance with Augumentor which really helped in reducing the overfit considerbaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the Model_2 on test dataset\n",
    "loss_test, accuracy_test = model_2.evaluate(test_ds, verbose=1,)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \", accuracy_test)\n",
    "\n",
    "print(\"Loss: \",loss_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings \n",
    "\n",
    "#### Accuracy and Loss of the test Data Set  is quite similar to the Train Data set."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "0-AUR_b7UcaK",
    "4csQL1dvO0b2"
   ],
   "name": "raghul_ranganathan_nn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
